{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dutch Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure installation has succeeded\n",
    "import tempo_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload now\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from tempo_embeddings.text.corpus import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo_embeddings.embeddings.vector_database import ChromaDatabaseManager\n",
    "\n",
    "MODEL_NAME = \"NetherlandsForensicInstitute/robbert-2022-dutch-sentence-transformers\"\n",
    "\n",
    "db = ChromaDatabaseManager(db_path=\"testing_db\", embedder_name=MODEL_NAME, batch_size=24)\n",
    "db.connect()\n",
    "\n",
    "duurzam_collection = db.get_existing_collection(\"anp_duurzam\")\n",
    "anp_duurzam = db.get_corpus(duurzam_collection, include_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in anp_duurzam.passages[:20]:\n",
    "    print(len(p), p)\n",
    "\n",
    "corpus = anp_duurzam\n",
    "corpus.embeddings = db.compress_embeddings(corpus)\n",
    "\n",
    "if corpus.embeddings is not None:\n",
    "    print(corpus.embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --continue https://raw.githubusercontent.com/Semantics-of-Sustainability/tempo-embeddings/main/tempo_embeddings/data/stopwords-filter-nl.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_file = Path(\"stopwords-filter-nl.txt\")\n",
    "\n",
    "with open(stopwords_file.absolute(), \"rt\") as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "stopwords.update(\n",
    "    {\n",
    "        \"wij\",\n",
    "        \"we\",\n",
    "        \"moeten\",\n",
    "        \"heer\",\n",
    "        \"mevrouw\",\n",
    "        \"minister\",\n",
    "        \"voorzitter\",\n",
    "        \"gaat\",\n",
    "        \"wel\",\n",
    "        \"den\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload now\n",
    "\n",
    "# Arguments: min_cluster_size=10, cluster_selection_epsilon=0.1, ...\n",
    "# See https://scikit-learn.org/stable/modules/generated/sklearn.cluster.HDBSCAN.html for full list\n",
    "\n",
    "# e.g. min_samples=10, cluster_selection_epsilon=0.2, cluster_selection_method=\"leaf\"\n",
    "FILTER_TERMS = [\"duurzaam\"] \n",
    "clusters = corpus.cluster(min_cluster_size=10, cluster_selection_epsilon=0.1)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    cluster.set_topic_label(exclude_words=frozenset(stopwords | set(FILTER_TERMS)), n=5)\n",
    "    print(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clusters.txt\", \"wt\") as f:\n",
    "    for cluster in clusters:\n",
    "        print(\n",
    "            \", \".join(\n",
    "                cluster.top_words(\n",
    "                    exclude_words=frozenset(stopwords | set(FILTER_TERMS)), n=5\n",
    "                )\n",
    "            ),\n",
    "            file=f,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload now\n",
    "\n",
    "from tempo_embeddings.visualization.clusters import ClusterVisualizer\n",
    "\n",
    "visualizer = ClusterVisualizer(*clusters)\n",
    "visualizer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "from tempo_embeddings.visualization.bokeh import BokehInteractiveVisualizer\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "visualizer = BokehInteractiveVisualizer(\n",
    "    *clusters, metadata_fields=corpus.metadata_fields(), width=2000, height=1000\n",
    ")\n",
    "\n",
    "os.environ[\n",
    "    \"BOKEH_ALLOW_WS_ORIGIN\"\n",
    "] = \"*\"\n",
    "\n",
    "show(visualizer.create_document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
